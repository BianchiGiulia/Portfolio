{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pWfUHtClvZyC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import time\n",
    "from numpy.core.memmap import ndarray\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zquQ6njN9Cgo",
    "outputId": "13d3bdbc-1f7c-4294-c344-8c9bea4b0fb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/giulia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_H3fl56evS1"
   },
   "source": [
    "## **Loading a word embedding (WE) model**\n",
    "For this project the [Word2Vec](https://code.google.com/archive/p/word2vec/) pre-trained word embedding has been choosen. It consists of about 100 billion words translated into 300-dimensional vectors for 3 million words and phrases from the Google News dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-RMMpcvrvZyI"
   },
   "outputs": [],
   "source": [
    "path = 'word_vectors2.kv'\n",
    "if os.path.exists(path):\n",
    "    word_vectors = KeyedVectors.load(path)\n",
    "else:\n",
    "    #model = api.load(\"glove-twitter-25\")\n",
    "    model = api.load('word2vec-google-news-300')\n",
    "    word_vectors = model.wv\n",
    "    word_vectors.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1XF3ythe2ph"
   },
   "source": [
    "## **Calculating word-to-word similarities**\n",
    "The selected source words are the following: <b>Paris, magic, food, sleep, elegant. </b><br> We created a dictionary with <b>source words as keys</b> and 6 <b>tuples consisting of target word and rank as values</b>. The range of our personal classification goes from 1 (most related) to 6 (least related). As a rule of thumb, we tried to keep the ratio between this two antipodes to 50/50. <br>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-color:#9ABAD9;border-spacing:0;}\n",
    ".tg td{background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#444;\n",
    "  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#fff;\n",
    "  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">source words&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;            </th>\n",
    "    <th class=\"tg-0pky\">target words<br>+<br>human ranking  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         </th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">Paris</td>\n",
    "    <td class=\"tg-0pky\">1. France<br>2. croissant<br>3. Rome<br>4. civilization<br>5. sand<br>6. orthodontist</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">magic</td>\n",
    "    <td class=\"tg-0pky\">1. illusion<br>2. black<br>3. rabbit<br>4.nice<br>5. rice<br>6. sad</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">food</td>\n",
    "    <td class=\"tg-0pky\">1. pizza<br>2. water<br>3. hot<br>4. bar<br>5. happy<br>6. machine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">sleep</td>\n",
    "    <td class=\"tg-0pky\">1. night<br>2. nightmare<br>3. pillow<br>4. brother<br>5. broken<br>6. rave</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">elegant</td>\n",
    "    <td class=\"tg-0pky\">1. suit<br>2. princess<br>3. funny<br>4. math<br>5. tattoo<br>6. alligator</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XRcsmiVfO7b"
   },
   "source": [
    "**Implementation**<br><br>\n",
    "The function `cos_sim` takes as argument two vectors `a, b` and calculates their normalized dot product according to the formula:<br><br>\n",
    "$$ \\bf \\text{cos}(x,y) = \\frac{a}{\\lVert a \\rVert _2} \\cdot \\frac{b^T}{\\lVert b \\rVert _2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "122tifuvUTAN"
   },
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    dot_product = np.matmul(a, b.T)\n",
    "    norm_a = np.linalg.norm(a) \n",
    "    norm_b = np.linalg.norm(b)\n",
    "    ret_val = dot_product / (norm_a * norm_b)\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, the vectors designated for \"Italy\" and \"pizza\" show to have a cosine similarity of ~0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jZnEj0svPXJR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15924986"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "italy = word_vectors.get_vector(\"italy\")\n",
    "pizza = word_vectors.get_vector(\"pizza\")\n",
    "cos_sim(pizza,italy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zsUDLIlBzKah"
   },
   "outputs": [],
   "source": [
    "source_words = [\"paris\", \"magic\", \"food\", \"sleep\", \"elegant\"]\n",
    "words_ = {\"paris\": [(\"france\",1), (\"croissant\", 2), (\"civilization\",4), (\"orthodontist\",6), (\"rome\", 3), (\"sand\", 5) ], #tuple (word, rank)\n",
    "               \"magic\": [(\"rabbit\",3), (\"black\",2), (\"nice\",4), (\"rice\",5), (\"illusion\",1), (\"sad\",6)], \n",
    "               \"food\": [(\"pizza\",1), (\"bar\",4),( \"machine\",6), (\"water\",2), (\"happy\",5), (\"hot\",3)], \n",
    "               \"sleep\": [(\"brother\",4), (\"rave\",6), (\"pillow\",3), (\"night\",1),( \"nightmare\",2), (\"broken\",5)], \n",
    "               \"elegant\": [(\"alligator\",6), (\"princess\",2),( \"suit\",1), (\"tattoo\",5), (\"funny\",3), (\"mathematics\",4)] } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhQvuDL1fnfV"
   },
   "source": [
    "**Reporting and observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we display a set of five tables, each of which displays the cosine similarity computed with the function hereabove implemented and our human ranking on the right. In all cases but one the first three most similar words corresponds with words ranked in the first three places, just in slightly different order. Overall the cosine similarity reflects the expectation, and the only anomaly concern the word <b>\"magic\"</b>: in our expectation this word had a better relationship with the adjective <b>\"black\"</b>, but considering the source of the embeddings, namely, Google News, this is not surprising: it is quite rare to find article about black magic, in daily news, in 2022. It is worth noticing that among all source/target words, the maximum value reached is <b>~0.55</b> between <b>\"Paris\" and \"France\"</b>, as we expected a much higher value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1mCjfvA010j6",
    "outputId": "dda1fdb5-f477-4e65-aae6-e91e31e1fe8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>paris</th>\n",
       "      <th>human rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>france</td>\n",
       "      <td>0.555080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rome</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>croissant</td>\n",
       "      <td>0.299126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sand</td>\n",
       "      <td>0.159037</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>civilization</td>\n",
       "      <td>0.110888</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orthodontist</td>\n",
       "      <td>0.079406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             __     paris  human rank\n",
       "0        france  0.555080           1\n",
       "4          rome  0.546584           3\n",
       "1     croissant  0.299126           2\n",
       "5          sand  0.159037           5\n",
       "2  civilization  0.110888           4\n",
       "3  orthodontist  0.079406           6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>magic</th>\n",
       "      <th>human rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>illusion</td>\n",
       "      <td>0.366176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>0.251940</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.218269</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>0.171964</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sad</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rice</td>\n",
       "      <td>0.063786</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         __     magic  human rank\n",
       "4  illusion  0.366176           1\n",
       "0    rabbit  0.251940           3\n",
       "2      nice  0.218269           4\n",
       "1     black  0.171964           2\n",
       "5       sad  0.136849           6\n",
       "3      rice  0.063786           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>food</th>\n",
       "      <th>human rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pizza</td>\n",
       "      <td>0.443432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water</td>\n",
       "      <td>0.395679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.185422</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>0.181046</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.055477</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        __      food  human rank\n",
       "0    pizza  0.443432           1\n",
       "3    water  0.395679           2\n",
       "5      hot  0.185422           3\n",
       "1      bar  0.181046           4\n",
       "4    happy  0.055477           5\n",
       "2  machine  0.003741           6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>sleep</th>\n",
       "      <th>human rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pillow</td>\n",
       "      <td>0.366484</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>night</td>\n",
       "      <td>0.285409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nightmare</td>\n",
       "      <td>0.120137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rave</td>\n",
       "      <td>0.108205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brother</td>\n",
       "      <td>0.103987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>broken</td>\n",
       "      <td>0.043387</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          __     sleep  human rank\n",
       "2     pillow  0.366484           3\n",
       "3      night  0.285409           1\n",
       "4  nightmare  0.120137           2\n",
       "1       rave  0.108205           6\n",
       "0    brother  0.103987           4\n",
       "5     broken  0.043387           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>elegant</th>\n",
       "      <th>human rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>funny</td>\n",
       "      <td>0.238420</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>princess</td>\n",
       "      <td>0.217093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suit</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alligator</td>\n",
       "      <td>0.126078</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.067425</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tattoo</td>\n",
       "      <td>0.028919</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            __   elegant  human rank\n",
       "4        funny  0.238420           3\n",
       "1     princess  0.217093           2\n",
       "2         suit  0.131944           1\n",
       "0    alligator  0.126078           6\n",
       "5  mathematics  0.067425           4\n",
       "3       tattoo  0.028919           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in words_.items():\n",
    "    key_v = word_vectors.get_vector(key)\n",
    "    comp_results = pd.DataFrame(columns = ['__']+[key,\"human rank\"])\n",
    "\n",
    "    for word in value:\n",
    "        t = cos_sim(key_v,word_vectors.get_vector(word[0])) \n",
    "        comp_results.loc[len(comp_results)] = [word[0],t, word[1]]\n",
    "\n",
    "    comp_results = comp_results.sort_values(key, ascending=False)\n",
    "\n",
    "    display(comp_results)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-DrOxBmUMYB"
   },
   "source": [
    "# **Calculating nearest neighbors**\n",
    "In this phase, we retrieve the  𝑘=10  nearest neighbors using the word embedding model.<br><br>\n",
    "<b>Efficiency </b><br><br>\n",
    "To ensure a efficient calculation of the dot product we refashion the input via `np.newaxis` function: <br>\n",
    "First we define the numerator dot product operation; <i>\" the denominator p1 can be read like: make the vector vertical (:) and add a column dimension and p2 can be read like: add a row dimension, make the vector horizontal. This operation for p2 in theory is not necessary because p2 was already horizontal\"$^1$ <br><br> <small>$^1$[source](https://towardsdatascience.com/cosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3)</i> </small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PGntlzE7QMj-"
   },
   "outputs": [],
   "source": [
    "def csm(A:ndarray,B:ndarray)->float: \n",
    "    dot_product=np.matmul(A,B.T)\n",
    "    p1= np.linalg.norm(A)#np.sqrt(np.sum(A**2,axis=1))[:,np.newaxis]\n",
    "    p2=np.sqrt(np.sum(B**2,axis=1))[np.newaxis,:]\n",
    "    ret_val = dot_product/(p1*p2)\n",
    "    return ret_val[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall implementation**\n",
    "<br><br>\n",
    "the implemented function `knn` takes a source vector, a set of target vectors, and the  𝑘  parameter, and returns the  𝑘  nearest neighbors together with two similarity scores: dot product and cosine similarity (implemented via `csm` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u0ZsHG0-v3E6"
   },
   "outputs": [],
   "source": [
    "def knn(source,target,k=10):  \n",
    "    r = csm(source, target)\n",
    "\n",
    "    cos_sim =np.argsort(r)[::-1]\n",
    "    dot = source @ target.T\n",
    "\n",
    "    index_dot = np.argsort(dot)[::-1]\n",
    "\n",
    "    return {\"dot product\":{\"order\": index_dot[0:k], \"value\": sorted(dot, reverse=True)[0:k]}, \"cosin\":{\"order\": cos_sim[0:k], \"value\": sorted(r, reverse = True)[0:k]} }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporting and observations**<br><br>\n",
    "In the following it is shown a table for each source word, the <b>rows</b> display:<br><br>\n",
    "-the rank order of target words produced by the metrics <b>[order]</b><br>\n",
    "-the similarity value of target words<b> [value]</b><br>\n",
    "-the target words <b>[words]</b><br><br>\n",
    "while the two <b>columns</b> concern respectively the dot product and the cosine similarity measures.<br>\n",
    "Not surprisingly we notice almosta a 1:1 correspondence in the outcome of the two measures. This is probably due to the fact that dot product, if normalized, actually corresponds to cosine similarity (this also explain why dot product has a wider output range than cosine similarity). The differences, to be found only in the case of the word <b>\"elegant\"</b>, can be explained by the observation that being <b>the only adjective</b> it is more versatile, i.e. it can be tied to a different selection of nouns, whereas nouns and verbs have a more pronounced semantic belonging between themselves. From a mathematical point of view, it can also be that differences depend by the fact that dot product takes into account the <b>lenghts and occurrences</b> of words, whereas cosine similarity is not magnitude sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PSrbkULKYz9z",
    "outputId": "6977688f-02d8-4915-f276-9a8b19ef562f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  paris\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot product</th>\n",
       "      <th>cosin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>[0, 4, 1, 5, 2, 3]</td>\n",
       "      <td>[0, 4, 1, 5, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>[6.7056293, 5.128788, 3.4958282, 1.5757673, 1.2555757, 0.97523594]</td>\n",
       "      <td>[0.5550795, 0.5465838, 0.29912594, 0.1590366, 0.11088846, 0.07940605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>[france, rome, croissant, sand, civilization, orthodontist]</td>\n",
       "      <td>[france, rome, croissant, sand, civilization, orthodontist]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              dot product  \\\n",
       "order                                                  [0, 4, 1, 5, 2, 3]   \n",
       "value  [6.7056293, 5.128788, 3.4958282, 1.5757673, 1.2555757, 0.97523594]   \n",
       "words         [france, rome, croissant, sand, civilization, orthodontist]   \n",
       "\n",
       "                                                                       cosin  \n",
       "order                                                     [0, 4, 1, 5, 2, 3]  \n",
       "value  [0.5550795, 0.5465838, 0.29912594, 0.1590366, 0.11088846, 0.07940605]  \n",
       "words            [france, rome, croissant, sand, civilization, orthodontist]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "key:  magic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot product</th>\n",
       "      <th>cosin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>[4, 0, 2, 1, 5, 3]</td>\n",
       "      <td>[4, 0, 2, 1, 5, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>[3.170901, 2.0277839, 1.7034643, 1.2302322, 1.1537026, 0.6292146]</td>\n",
       "      <td>[0.36617595, 0.25194007, 0.2182694, 0.17196375, 0.13684875, 0.063786276]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>[illusion, rabbit, nice, black, sad, rice]</td>\n",
       "      <td>[illusion, rabbit, nice, black, sad, rice]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             dot product  \\\n",
       "order                                                 [4, 0, 2, 1, 5, 3]   \n",
       "value  [3.170901, 2.0277839, 1.7034643, 1.2302322, 1.1537026, 0.6292146]   \n",
       "words                         [illusion, rabbit, nice, black, sad, rice]   \n",
       "\n",
       "                                                                          cosin  \n",
       "order                                                        [4, 0, 2, 1, 5, 3]  \n",
       "value  [0.36617595, 0.25194007, 0.2182694, 0.17196375, 0.13684875, 0.063786276]  \n",
       "words                                [illusion, rabbit, nice, black, sad, rice]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "key:  food\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot product</th>\n",
       "      <th>cosin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>[0, 3, 5, 1, 4, 2]</td>\n",
       "      <td>[0, 3, 5, 1, 4, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>[3.7765813, 2.7387886, 1.3421888, 1.2980336, 0.36545038, 0.026318029]</td>\n",
       "      <td>[0.44343227, 0.39567885, 0.1854218, 0.1810458, 0.055477098, 0.0037409926]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>[pizza, water, hot, bar, happy, machine]</td>\n",
       "      <td>[pizza, water, hot, bar, happy, machine]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 dot product  \\\n",
       "order                                                     [0, 3, 5, 1, 4, 2]   \n",
       "value  [3.7765813, 2.7387886, 1.3421888, 1.2980336, 0.36545038, 0.026318029]   \n",
       "words                               [pizza, water, hot, bar, happy, machine]   \n",
       "\n",
       "                                                                           cosin  \n",
       "order                                                         [0, 3, 5, 1, 4, 2]  \n",
       "value  [0.44343227, 0.39567885, 0.1854218, 0.1810458, 0.055477098, 0.0037409926]  \n",
       "words                                   [pizza, water, hot, bar, happy, machine]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "key:  sleep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot product</th>\n",
       "      <th>cosin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>[2, 3, 4, 1, 0, 5]</td>\n",
       "      <td>[2, 3, 4, 1, 0, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>[3.830201, 1.9355688, 1.18206, 1.0496868, 0.90746963, 0.38045508]</td>\n",
       "      <td>[0.36648425, 0.28540924, 0.12013676, 0.10820493, 0.10398727, 0.0433865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>[pillow, night, nightmare, rave, brother, broken]</td>\n",
       "      <td>[pillow, night, nightmare, rave, brother, broken]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             dot product  \\\n",
       "order                                                 [2, 3, 4, 1, 0, 5]   \n",
       "value  [3.830201, 1.9355688, 1.18206, 1.0496868, 0.90746963, 0.38045508]   \n",
       "words                  [pillow, night, nightmare, rave, brother, broken]   \n",
       "\n",
       "                                                                         cosin  \n",
       "order                                                       [2, 3, 4, 1, 0, 5]  \n",
       "value  [0.36648425, 0.28540924, 0.12013676, 0.10820493, 0.10398727, 0.0433865]  \n",
       "words                        [pillow, night, nightmare, rave, brother, broken]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "key:  elegant\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot product</th>\n",
       "      <th>cosin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>[1, 4, 0, 2, 5, 3]</td>\n",
       "      <td>[4, 1, 2, 0, 5, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>[2.0062206, 1.8845644, 1.3815546, 1.0915424, 0.57979035, 0.3136271]</td>\n",
       "      <td>[0.23842005, 0.21709342, 0.13194413, 0.12607822, 0.067424625, 0.028918523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>[princess, funny, alligator, suit, mathematics, tattoo]</td>\n",
       "      <td>[funny, princess, suit, alligator, mathematics, tattoo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               dot product  \\\n",
       "order                                                   [1, 4, 0, 2, 5, 3]   \n",
       "value  [2.0062206, 1.8845644, 1.3815546, 1.0915424, 0.57979035, 0.3136271]   \n",
       "words              [princess, funny, alligator, suit, mathematics, tattoo]   \n",
       "\n",
       "                                                                            cosin  \n",
       "order                                                          [4, 1, 2, 0, 5, 3]  \n",
       "value  [0.23842005, 0.21709342, 0.13194413, 0.12607822, 0.067424625, 0.028918523]  \n",
       "words                     [funny, princess, suit, alligator, mathematics, tattoo]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in words_.items():\n",
    "    target = []\n",
    "    key_v = word_vectors.get_vector(key) #wv\n",
    "    for i in value:\n",
    "        value_v = word_vectors.get_vector(i[0])\n",
    "        target.append(value_v)\n",
    "\n",
    "    target = np.array(target)\n",
    "    ret_val =knn(key_v,target )\n",
    "    words_c = []\n",
    "    for j in ret_val[\"cosin\"][\"order\"]:\n",
    "        words_c.append(value[j][0])\n",
    "  \n",
    "    ret_val[\"cosin\"][\"words\"] = words_c\n",
    "  \n",
    "    words_d = []\n",
    "    for j in ret_val[\"dot product\"][\"order\"]:\n",
    "        words_d.append(value[j][0])\n",
    "  \n",
    "    ret_val[\"dot product\"][\"words\"] = words_d\n",
    "\n",
    "    df = pd.DataFrame.from_dict(ret_val)\n",
    "\n",
    "    print(\"key: \", key)\n",
    "    display(df)\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION WITH WORD EMBEDDING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, we retrieve and use the same code of Assignment 1 to preprocess the three datasets and get our bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlLCUvvlpdyP",
    "outputId": "5c39555d-8455-4384-cc91-9b57efe9baec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8455801010131836\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "def cleaning_pipeline(df):\n",
    "    e_stopwords = stopwords.words('english')\n",
    "    train_list = df[\"text\"].values.tolist()\n",
    "    words_without_stopw = []\n",
    "    for sentence in train_list:\n",
    "        temp = []\n",
    "        for word in sentence.lower().split():\n",
    "            if word not in e_stopwords and  word.isalpha():\n",
    "                temp.append(word)\n",
    "        words_without_stopw.append(temp)\n",
    "    ret_df = pd.DataFrame({\"raw_words\": words_without_stopw, \"label\": df.label.values})\n",
    "    return ret_df\n",
    "\n",
    "def get_boW(l_of_words,k=100):\n",
    "    words = set()\n",
    "    for i in l_of_words:\n",
    "        counter = Counter(i).most_common(k)\n",
    "        words.update([i[0] for i in counter])\n",
    "    return words\n",
    "#------------------------------------------------------------#\n",
    "SPLITS = ['train', 'test', \"validation\"]\n",
    "datasets = { }\n",
    "\n",
    "#Load the train, validation, and test sets.\n",
    "path = \"nlp2022_23_data/thedeep.subset.{}.txt\"\n",
    "csv_header = ['idx', 'text', 'label']\n",
    "for split in SPLITS:\n",
    "        datasets[split] = {}\n",
    "        datasets[split]['df'] = cleaning_pipeline(pd.read_csv(path.format(split), names = csv_header))\n",
    "\n",
    "words = get_boW(datasets[\"train\"][\"df\"][\"raw_words\"].values)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iSQbLz2o8oD"
   },
   "source": [
    "**Map word embeddings to dictionary words**<br><br>\n",
    "For every word in the dictionary we recover the corresponding word embedding from the pre-trained model. <b>In 6871 instances (~31.7%) there was no match</b>, so the missing word-vector has been randomly initialized with values between the minimum and maximum in the word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "m8oPr_J6maj9",
    "outputId": "9ac0a4be-a6f6-448e-ec93-78511e4cb86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing word-vector representations: 6871\n"
     ]
    }
   ],
   "source": [
    "dict_ = {}\n",
    "count = 0\n",
    "temp = []\n",
    "min_ = 0\n",
    "max_ = 0\n",
    "for word in list(words):\n",
    "    try:\n",
    "        embedd_w = word_vectors.get_vector(word)\n",
    "        if min(embedd_w) < min_:\n",
    "            min_ = min(embedd_w)\n",
    "        if max(embedd_w) > max_:\n",
    "            max_ = max(embedd_w)\n",
    "        dict_[word] = embedd_w\n",
    "    \n",
    "    except:\n",
    "        temp.append(word)\n",
    "        count += 1\n",
    "\n",
    "for word in temp:\n",
    "    dict_[word] = np.random.uniform(min_, max_, 300) \n",
    "\n",
    "   \n",
    "print(f'missing word-vector representations: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Document embedding as the average of word embeddings**<br>\n",
    "In the following we implemented the function `doc_representation` which takes as input:<br> `df`: a dataframe containing the 21689 documents;<br>`words`: a list of words to fetch the corresponding vector representation. By iterating over them it produces a representation of the whole document space based on the mean of word embeddings, as described thereunder:"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_representation(df,words):\n",
    "    d = df[\"raw_words\"].values.tolist() \n",
    "    doc_repr = [] \n",
    "    for i in d:\n",
    "        single_doc = []\n",
    "        w = words.intersection(i) \n",
    "        \n",
    "        for word in w:           \n",
    "            single_doc.append(dict_.get(word))\n",
    "        \n",
    "        \n",
    "        if len(w) > 0:\n",
    "            \n",
    "            single_doc = np.mean(single_doc, axis=0)\n",
    "            doc_repr.append(single_doc)\n",
    "        else:\n",
    "            doc_repr.append(np.repeat(0, 300))\n",
    "    ret_df = pd.DataFrame()\n",
    "    ret_df[\"representation\"] = doc_repr\n",
    "    ret_df[\"label\"] = df[\"label\"]  \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6124680042266846\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for split in SPLITS:\n",
    "    datasets[split][\"embeddings\"] = doc_representation(datasets[split][\"df\"],words) \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Classification and evaluation**\n",
    "We applied four* classification algorithms which are best suited for a multilabe classification task, i.e.:<br><br><b>\n",
    "-K-nearest neighbors algorithm (k-NN)<br>\n",
    "-Random Forest (RF)<br>\n",
    "-Multi Layer Perceptron (MLP)<br>\n",
    "-Singular Value Decomposition (SVD)<br><br></b>\n",
    "We first used the validation set to find the optimal hyperparameters, then deployed the models on the test set.\n",
    "It is worth mentioning that a previous version of this project use the embedding of GloVe Twitter, but we choose to change it since the one actually utilized hel way higher accuracy.<br><br>\n",
    "<i>*not three because we suspect something went wrong with MLP since it helds the same accuracy for very different hyperparameters</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors algorithm (k-NN)\n",
    "**Validation set**<br>\n",
    "After an initial choiche of hyperparameter in the range 5 to 100 we downsized the best choices between 20 and 30 neighbours. <br>One of the best choiche is 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of KNN with 20 neighbours on validation set: 0.6590909090909091\n",
      "accuracy of KNN with 22 neighbours on validation set: 0.6610169491525424\n",
      "accuracy of KNN with 25 neighbours on validation set: 0.6579352850539292\n",
      "accuracy of KNN with 27 neighbours on validation set: 0.6544684129429892\n",
      "accuracy of KNN with 30 neighbours on validation set: 0.6536979969183359\n"
     ]
    }
   ],
   "source": [
    "neighbours = [20, 22, 25, 27, 30]\n",
    "\n",
    "for nn in neighbours:\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=nn) \n",
    "    y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "    \n",
    "    model = model.fit(X_train, y)\n",
    "    \n",
    "    X_validation = datasets[\"validation\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "    y_pred = model.predict(X_validation)\n",
    "    y_true = datasets[\"validation\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    \n",
    "    acc= accuracy_score(y_true, y_pred)\n",
    "    print(f\"accuracy of KNN with {nn} neighbours on validation set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of NKK on test-set: 0.6716763005780347\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=22)\n",
    "y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "\n",
    "model = model.fit(X_train, y)\n",
    "\n",
    "X_test = datasets[\"test\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = datasets[\"test\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    \n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"accuracy of NKK on test-set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "**Validation set**<br>\n",
    "Best parameter for number of estimator: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Random Forest with 35 estimators on validation set: 0.6047765793528506\n",
      "accuracy of Random Forest with 55 estimators on validation set: 0.6221109399075501\n",
      "accuracy of Random Forest with 70 estimators on validation set: 0.6224961479198767\n",
      "accuracy of Random Forest with 100 estimators on validation set: 0.6251926040061633\n",
      "accuracy of Random Forest with 200 estimators on validation set: 0.6336671802773498\n"
     ]
    }
   ],
   "source": [
    "estimators= [35, 55, 70, 100, 200]\n",
    "\n",
    "for num in estimators:\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators= num)\n",
    "    y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "    \n",
    "    model = model.fit(X_train, y)\n",
    "    \n",
    "    X_validation = datasets[\"validation\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "    y_pred = model.predict(X_validation)\n",
    "    y_true = datasets[\"validation\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"accuracy of Random Forest with {num} estimators on validation set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Random Forest on test-set: 0.6385356454720617\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "\n",
    "model = model.fit(X_train, y)\n",
    "\n",
    "X_test = datasets[\"test\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = datasets[\"test\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    \n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"accuracy of Random Forest on test-set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "**Validation set**<br>\n",
    "Increasing the number of hidden layers showed to be not as useful as increasing the number of neurons. <br>\n",
    "All parameters seems to held the same accuracy, furthermore the accuracy on the test-set is suspiciously higher than on validation set, hinting a case of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Multi Layer Perceptron with (25, 50) hidden units on validation set: 0.6458574181117533\n",
      "accuracy of Multi Layer Perceptron with (25,) hidden units on validation set: 0.6458574181117533\n",
      "accuracy of Multi Layer Perceptron with (50,) hidden units on validation set: 0.6458574181117533\n",
      "accuracy of Multi Layer Perceptron with (100,) hidden units on validation set: 0.6458574181117533\n",
      "accuracy of Multi Layer Perceptron with (300,) hidden units on validation set: 0.6458574181117533\n",
      "accuracy of Multi Layer Perceptron with (1000,) hidden units on validation set: 0.6458574181117533\n"
     ]
    }
   ],
   "source": [
    "layer_size= [(25,50), (25,), (50,), (100,), (300,), (1000,)]\n",
    "\n",
    "for num in layer_size:\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes= num)\n",
    "    y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "    \n",
    "    model = model.fit(X_train, y)\n",
    "    \n",
    "    X_validation = datasets[\"validation\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "    y_pred = model.predict(X_validation)\n",
    "    y_true = datasets[\"validation\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    \n",
    "    acc_ = accuracy_score(y_true, y_pred)\n",
    "    print(f\"accuracy of Multi Layer Perceptron with {num} hidden units on validation set: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Multi Layer Perceptron on test-set: 0.7526011560693642\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes= num)\n",
    "y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "\n",
    "model = model.fit(X_train, y)\n",
    "\n",
    "X_test = datasets[\"test\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = datasets[\"test\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "    \n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"accuracy of Multi Layer Perceptron on test-set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)\n",
    "**Validation set**<br>\n",
    "Assignment 1 revealed an imbalance in the data, therefore SVD was implemented with higher weights for the classes less represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_weights = {0:.2, 2:.1, 3:.1, 4:.0, 5:0, 6:.2, 7:.2, 8:.1, 9:0, 10:.0, 11:.0}"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SVD on test-set: 0.6385356454720617\n"
     ]
    }
   ],
   "source": [
    "model= svm.SVC(class_weight=c_weights)\n",
    "y = datasets[\"train\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "X_train = datasets[\"train\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "\n",
    "model = model.fit(X_train, y)\n",
    "\n",
    "X_validation = datasets[\"test\"][\"embeddings\"][\"representation\"].values.tolist()\n",
    "y_pred = model.predict(X_validation)\n",
    "y_true = datasets[\"test\"][\"embeddings\"][\"label\"].values.tolist()\n",
    "\n",
    "acc_ = accuracy_score(y_true, y_pred)\n",
    "print(f\"accuracy of SVD on test-set: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KKsmhp8vZyQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
